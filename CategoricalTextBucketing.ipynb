{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be697367-63d6-415a-94cf-656d4e56e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product Detailed_Category  Price Concise_Category\n",
      "0  Smartphone        Smartphone    500         Clothing\n",
      "1      Laptop            Laptop   1000         Clothing\n",
      "2     T-Shirt           T-Shirt     20       Home Goods\n",
      "3     Dresser           Dresser    150         Clothing\n",
      "4   Microwave         Microwave     80         Clothing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/_b3wjgjx2lj2gcds3k7c3mnw0000gn/T/ipykernel_38189/992735926.py:25: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarities = [text_doc.similarity(category_doc) for category_doc in categories_docs]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import pandas as pd\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample DataFrames\n",
    "concise_categories = ['Electronics', 'Clothing', 'Home Goods']\n",
    "detailed_categories = ['Smartphone', 'Laptop', 'T-Shirt', 'Dresser', 'Microwave']\n",
    "\n",
    "# Sample DataFrame with detailed categories\n",
    "detailed_categories_df = pd.DataFrame({\n",
    "    'Product': ['Smartphone', 'Laptop', 'T-Shirt', 'Dresser', 'Microwave'],\n",
    "    'Detailed_Category': detailed_categories,\n",
    "    'Price': [500, 1000, 20, 150, 80]\n",
    "})\n",
    "\n",
    "# Process concise categories with spaCy\n",
    "concise_categories_docs = [nlp(category) for category in concise_categories]\n",
    "\n",
    "# Define a function to find the best match using spaCy\n",
    "def find_best_match_spacy(text, categories_docs):\n",
    "    text_doc = nlp(text)\n",
    "    similarities = [text_doc.similarity(category_doc) for category_doc in categories_docs]\n",
    "    best_match_index = similarities.index(max(similarities))\n",
    "    return concise_categories[best_match_index]\n",
    "\n",
    "# Map detailed categories to concise categories using spaCy\n",
    "detailed_categories_df['Concise_Category'] = detailed_categories_df['Detailed_Category'].apply(\n",
    "    lambda x: find_best_match_spacy(x, concise_categories_docs)\n",
    ")\n",
    "\n",
    "# If there are unmatched categories, handle them as needed (e.g., assign a default category)\n",
    "detailed_categories_df['Concise_Category'].fillna('Other', inplace=True)\n",
    "\n",
    "# Now, you have a DataFrame with concise categories\n",
    "print(detailed_categories_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56aebf7c-c509-4ad9-8d63-f80b8931ad34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product Detailed_Category  Price Concise_Category\n",
      "0  Smartphone        Smartphone    500      Electronics\n",
      "1      Laptop            Laptop   1000      Electronics\n",
      "2     T-Shirt           T-Shirt     20         Clothing\n",
      "3     Dresser           Dresser    150      Electronics\n",
      "4   Microwave         Microwave     80      Electronics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/_b3wjgjx2lj2gcds3k7c3mnw0000gn/T/ipykernel_38189/3507565840.py:27: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  spacy_similarities = [text_doc.similarity(category_doc) for category_doc in categories_docs]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample DataFrames\n",
    "concise_categories = ['Electronics', 'Clothing', 'Home Goods']\n",
    "detailed_categories = ['Smartphone', 'Laptop', 'T-Shirt', 'Dresser', 'Microwave']\n",
    "\n",
    "# Sample DataFrame with detailed categories\n",
    "detailed_categories_df = pd.DataFrame({\n",
    "    'Product': ['Smartphone', 'Laptop', 'T-Shirt', 'Dresser', 'Microwave'],\n",
    "    'Detailed_Category': detailed_categories,\n",
    "    'Price': [500, 1000, 20, 150, 80]\n",
    "})\n",
    "\n",
    "# Process concise categories with spaCy\n",
    "concise_categories_docs = [nlp(category) for category in concise_categories]\n",
    "\n",
    "# Define a function to find the best match using spaCy and fuzzy matching\n",
    "def find_best_match(text, categories_docs):\n",
    "    text_doc = nlp(text)\n",
    "    \n",
    "    # Calculate similarity using spaCy\n",
    "    spacy_similarities = [text_doc.similarity(category_doc) for category_doc in categories_docs]\n",
    "    \n",
    "    # Calculate similarity using fuzzywuzzy\n",
    "    fuzzy_similarities = [fuzz.partial_ratio(text, category) for category in concise_categories]\n",
    "    \n",
    "    # Combine spaCy and fuzzywuzzy scores\n",
    "    combined_similarities = [0.4 * spacy_sim + 0.6 * fuzzy_sim for spacy_sim, fuzzy_sim in zip(spacy_similarities, fuzzy_similarities)]\n",
    "    \n",
    "    # Find the best match index\n",
    "    best_match_index = combined_similarities.index(max(combined_similarities))\n",
    "    \n",
    "    return concise_categories[best_match_index]\n",
    "\n",
    "# Map detailed categories to concise categories using spaCy and fuzzy matching\n",
    "detailed_categories_df['Concise_Category'] = detailed_categories_df['Detailed_Category'].apply(\n",
    "    lambda x: find_best_match(x, concise_categories_docs)\n",
    ")\n",
    "\n",
    "# If there are unmatched categories, handle them as needed (e.g., assign a default category)\n",
    "detailed_categories_df['Concise_Category'].fillna('Other', inplace=True)\n",
    "\n",
    "# Now, you have a DataFrame with concise categories\n",
    "print(detailed_categories_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d3e3b3d-f15f-460c-ae0f-6f8b0d1d1759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product Detailed_Category  Price Concise_Category\n",
      "0  Smartphone        Smartphone    500      Electronics\n",
      "1      Laptop            Laptop   1000      Electronics\n",
      "2     T-Shirt           T-Shirt     20         Clothing\n",
      "3     Dresser           Dresser    150      Electronics\n",
      "4   Microwave         Microwave     80      Electronics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/_b3wjgjx2lj2gcds3k7c3mnw0000gn/T/ipykernel_38189/719447115.py:25: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  spacy_similarities = [text_doc.similarity(category_doc) for category_doc in categories_docs]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample DataFrames\n",
    "concise_categories = ['Electronics', 'Clothing', 'Home Goods']\n",
    "detailed_categories = ['Smartphone', 'Laptop', 'T-Shirt', 'Dresser', 'Microwave']\n",
    "\n",
    "# Sample DataFrame with detailed categories\n",
    "detailed_categories_df = pd.DataFrame({\n",
    "    'Product': ['Smartphone', 'Laptop', 'T-Shirt', 'Dresser', 'Microwave'],\n",
    "    'Detailed_Category': detailed_categories,\n",
    "    'Price': [500, 1000, 20, 150, 80]\n",
    "})\n",
    "\n",
    "# Process concise categories with spaCy\n",
    "concise_categories_docs = [nlp(category) for category in concise_categories]\n",
    "\n",
    "# Define a function to find the best match using spaCy and fuzzy matching\n",
    "def find_best_match(text, categories_docs):\n",
    "    text_doc = nlp(text)\n",
    "    \n",
    "    # Calculate similarity using spaCy (experiment with different methods)\n",
    "    # spaCy method 1: text_doc.similarity(category_doc)\n",
    "    # spaCy method 2: text_doc.similarity(category_doc.vector)\n",
    "    spacy_similarities = [text_doc.similarity(category_doc) for category_doc in categories_docs]\n",
    "    \n",
    "    # Calculate similarity using fuzzywuzzy\n",
    "    fuzzy_similarities = [fuzz.partial_ratio(text, category) for category in concise_categories]\n",
    "    \n",
    "    # Experiment with different weight combinations\n",
    "    combined_similarities = [0.7 * spacy_sim + 0.3 * fuzzy_sim for spacy_sim, fuzzy_sim in zip(spacy_similarities, fuzzy_similarities)]\n",
    "    \n",
    "    # Fine-tune fuzzy matching threshold (experiment with different values)\n",
    "    threshold = 80\n",
    "    \n",
    "    # Find the best match index\n",
    "    best_match_index = combined_similarities.index(max(combined_similarities))\n",
    "    \n",
    "    return concise_categories[best_match_index]\n",
    "\n",
    "# Map detailed categories to concise categories using spaCy and fuzzy matching\n",
    "detailed_categories_df['Concise_Category'] = detailed_categories_df['Detailed_Category'].apply(\n",
    "    lambda x: find_best_match(x, concise_categories_docs)\n",
    ")\n",
    "\n",
    "# If there are unmatched categories, handle them as needed (e.g., assign a default category)\n",
    "detailed_categories_df['Concise_Category'].fillna('Other', inplace=True)\n",
    "\n",
    "# Now, you have a DataFrame with concise categories\n",
    "print(detailed_categories_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec599a1-392d-41c5-8387-07359fe21fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product Detailed_Category  Price Concise_Category\n",
      "0  Smartphone        Smartphone    500      Electronics\n",
      "1      Laptop            Laptop   1000      Electronics\n",
      "2     T-Shirt           T-Shirt     20         Clothing\n",
      "3     Dresser           Dresser    150       Home Goods\n",
      "4   Microwave         Microwave     80      Electronics\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_md\")  # Use en_core_web_md instead of en_core_web_sm\n",
    "\n",
    "# Sample DataFrames\n",
    "concise_categories = ['Electronics', 'Clothing', 'Home Goods']\n",
    "detailed_categories = ['Smartphone', 'Laptop', 'T-Shirt', 'Dresser', 'Microwave']\n",
    "\n",
    "# Sample DataFrame with detailed categories\n",
    "detailed_categories_df = pd.DataFrame({\n",
    "    'Product': ['Smartphone', 'Laptop', 'T-Shirt', 'Dresser', 'Microwave'],\n",
    "    'Detailed_Category': detailed_categories,\n",
    "    'Price': [500, 1000, 20, 150, 80]\n",
    "})\n",
    "\n",
    "# Process concise categories with spaCy\n",
    "concise_categories_docs = [nlp(category) for category in concise_categories]\n",
    "\n",
    "# Define a function to find the best match using spaCy and fuzzy matching\n",
    "def find_best_match(text, categories_docs):\n",
    "    text_doc = nlp(text)\n",
    "    \n",
    "    # Calculate similarity using spaCy (experiment with different methods)\n",
    "    # spaCy method 1: text_doc.similarity(category_doc)\n",
    "    # spaCy method 2: text_doc.similarity(category_doc.vector)\n",
    "    spacy_similarities = [text_doc.similarity(category_doc) for category_doc in categories_docs]\n",
    "    \n",
    "    # Calculate similarity using fuzzywuzzy\n",
    "    fuzzy_similarities = [fuzz.partial_ratio(text, category) for category in concise_categories]\n",
    "    \n",
    "    # Experiment with different weight combinations\n",
    "    combined_similarities = [0.7 * spacy_sim + 0.3 * fuzzy_sim for spacy_sim, fuzzy_sim in zip(spacy_similarities, fuzzy_similarities)]\n",
    "    \n",
    "    # Fine-tune fuzzy matching threshold (experiment with different values)\n",
    "    threshold = 80\n",
    "    \n",
    "    # Find the best match index\n",
    "    best_match_index = combined_similarities.index(max(combined_similarities))\n",
    "    \n",
    "    return concise_categories[best_match_index]\n",
    "\n",
    "# Map detailed categories to concise categories using spaCy and fuzzy matching\n",
    "detailed_categories_df['Concise_Category'] = detailed_categories_df['Detailed_Category'].apply(\n",
    "    lambda x: find_best_match(x, concise_categories_docs)\n",
    ")\n",
    "\n",
    "# If there are unmatched categories, handle them as needed (e.g., assign a default category)\n",
    "detailed_categories_df['Concise_Category'].fillna('Other', inplace=True)\n",
    "\n",
    "# Now, you have a DataFrame with concise categories\n",
    "print(detailed_categories_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c798bc31-fe0c-4981-a26b-4b728788a022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated category is: Mobile Devices\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def categorize_into_single_category(category1, category2, category3, category4):\n",
    "    # Mapping of electronic device categories to overarching categories\n",
    "    category_mapping = {\n",
    "        'Smartphone': 'Mobile Devices',\n",
    "        'Laptop': 'Computing Devices',\n",
    "        'Smart TV': 'Home Entertainment',\n",
    "        'Fitness Tracker': 'Wearable Devices',\n",
    "    }\n",
    "\n",
    "    # Load spaCy model\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "    # Create a list of input categories\n",
    "    input_categories = [category1, category2, category3, category4]\n",
    "\n",
    "    # Calculate similarity scores for each input category with the mapped categories\n",
    "    similarity_scores = {}\n",
    "    for input_category in input_categories:\n",
    "        input_category_doc = nlp(input_category)\n",
    "        for mapped_category, mapped_category_label in category_mapping.items():\n",
    "            mapped_category_doc = nlp(mapped_category)\n",
    "            similarity = input_category_doc.similarity(mapped_category_doc)\n",
    "            if mapped_category_label not in similarity_scores or similarity > similarity_scores[mapped_category_label]:\n",
    "                similarity_scores[mapped_category_label] = similarity\n",
    "\n",
    "    # Find the category with the highest similarity score\n",
    "    estimated_category = max(similarity_scores, key=similarity_scores.get)\n",
    "\n",
    "    return estimated_category\n",
    "\n",
    "# Example usage\n",
    "category1 = 'Smartphone'\n",
    "category2 = 'Laptop'\n",
    "category3 = 'Smart TV'\n",
    "category4 = 'Fitness Tracker'\n",
    "\n",
    "result = categorize_into_single_category(category1, category2, category3, category4)\n",
    "print(f'The estimated category is: {result}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f7840-850d-4064-acf9-dd8c4f6ac5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
